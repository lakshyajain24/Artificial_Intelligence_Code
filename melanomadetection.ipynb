{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras import models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Input, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir='Path to train Directry'\n",
    "test_dir='Path to test Directory'\n",
    "train=pd.read_csv('Path to train csv')\n",
    "test=pd.read_csv('Path to test csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "data=[]\n",
    "for i in range(train.shape[0]):\n",
    "    data.append(train_dir + train['image_name'].iloc[i]+'.jpg')\n",
    "    labels.append(train['diagnosis'].iloc[i])\n",
    "df=pd.DataFrame(data)\n",
    "df.columns=['images']\n",
    "df['diagnosis']=labels\n",
    "\n",
    "test_data=[]\n",
    "for i in range(test.shape[0]):\n",
    "    test_data.append(test_dir + test['image_name'].iloc[i]+'.jpg')\n",
    "df_test=pd.DataFrame(test_data)\n",
    "df_test.columns=['images']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df['images'],df['diagnosis'], test_size=0.2, random_state=1234)\n",
    "\n",
    "train=pd.DataFrame(X_train)\n",
    "train.columns=['images']\n",
    "train['diagnosis']=y_train\n",
    "\n",
    "validation=pd.DataFrame(X_val)\n",
    "validation.columns=['images']\n",
    "validation['diagnosis']=y_val\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train,\n",
    "    x_col='images',\n",
    "    y_col='diagnosis',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    validation,\n",
    "    x_col='images',\n",
    "    y_col='diagnosis',\n",
    "    target_size=(224, 224),\n",
    "    shuffle=False,\n",
    "    batch_size=256,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainning CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_fit = model.fit(train_generator, epochs=33, validation_data=validation_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = list(fit.history.keys())\n",
    "accuracy_metrics = fit.history[metrics[1]]\n",
    "print(\"Final validation accuracy is\", accuracy_metrics[-1]*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dataenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "775f200255bcbeb4decc39e3864ccf3f1de0731d3fcf3e7a728354b00b16ac5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
